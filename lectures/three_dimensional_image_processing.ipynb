{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import scipy.stats\n",
    "import skimage.exposure\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.io\n",
    "import skimage.measure\n",
    "import skimage.morphology\n",
    "import skimage.restoration\n",
    "import skimage.segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to three-dimensional image processing\n",
    "\n",
    "The `skimage` library represents images as `numpy` arrays. A single-channel, or grayscale, image is a 2D matrix of pixel intensities of shape `(row, column)`. We can construct a 3D volume as a series of 2D `planes`, giving 3D images the shape `(plane, row, column)`. Multichannel data adds a `channel` dimension in the final position containing color information. \n",
    "\n",
    "These conventions are summarized in the table below:\n",
    "\n",
    "\n",
    "|Image type|Coordinates|\n",
    "|:---|:---|\n",
    "|2D grayscale|(row, column)|\n",
    "|2D multichannel|(row, column, channel)|\n",
    "|3D grayscale|(plane, row, column)|\n",
    "|3D multichannel|(plane, row, column, channel)|\n",
    "\n",
    "Some 3D images are constructed with equal resolution in each dimension; e.g., a computer generated rendering of a sphere. Most experimental data captures one dimension at a lower resolution than the other two; e.g., photographing thin slices to approximate a 3D structure as a stack of 2D images. The distance between pixels in each dimension, called `spacing`, is encoded in a tuple and is accepted as a parameter by some `skimage` functions and can be used to adjust contributions to filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/Output and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three dimensional data can be loaded with `skimage.io.imread`. The data for this tutorial was provided by the Allen Institute for Cell Science. It has been downsampled by a factor of 4 in the `row` and `column` dimensions to reduce computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = skimage.io.imread(\"../images/cells.tif\")\n",
    "\n",
    "print(\"shape: {}\".format(data.shape))\n",
    "print(\"dtype: {}\".format(data.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance between pixels is defined in the image metadata when the image was captured. It is reported by the microscope used the image the cells. The `spacing` will be used to adjust contributions to filters and helps decide when to apply operations planewise. We've chosen to normalize it `1.0` in the `row` and `column` dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_spacing = (0.2900000, 0.0650000, 0.0650000)\n",
    "\n",
    "spacing = tuple(np.divide(original_spacing, original_spacing[1]))\n",
    "\n",
    "print(\"spacing: {}\".format(spacing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try visualizing the image with `skimage.io.imshow`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    skimage.io.imshow(data, cmap=\"gray\")\n",
    "except TypeError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too bad! `skimage.io.imshow` can only display grayscale and RGB(A) 2D images. We can use `skimage.io.imshow` to visualize 2D planes. By fixing one axis, we can observe three different views of the 3D image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_plane(ax, plane, cmap=\"gray\", title=None):\n",
    "    ax.imshow(plane, cmap=cmap)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, (a, b, c) = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "show_plane(a, data[32], title=\"Plane = 32\")\n",
    "show_plane(b, data[:, 128, :], title=\"Row = 128\")\n",
    "show_plane(c, data[:, :, 128], title=\"Column = 128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three-dimensional images can be viewed as a series of two-dimensional functions. The `display` helper function displays 30 planes of the provided image. By default, every other plane is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(im3d, cmap=\"gray\", step=2):\n",
    "    _, axes = plt.subplots(nrows=5, ncols=6, figsize=(16, 14))\n",
    "    \n",
    "    vmin = im3d.min()\n",
    "    vmax = im3d.max()\n",
    "    \n",
    "    for ax, image in zip(axes.flatten(), im3d[::step]):\n",
    "        ax.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for plotting histograms.\n",
    "def plot_hist(ax, data, title=None):\n",
    "    ax.hist(data.ravel(), bins=256)\n",
    "    ax.ticklabel_format(axis=\"y\", style=\"scientific\", scilimits=(0, 0))\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skimage.expsoure` contains a number of functions for adjusting image contrast. These functions operate on pixel values. Generally, image dimensionality or pixel spacing does not need to be considered.\n",
    "\n",
    "[Gamma correction](https://en.wikipedia.org/wiki/Gamma_correction), also known as Power Law Transform, brightens or darkens an image. The function `O = I**gamma` is applied to each pixel in the image. A `gamma < 1` will brighten an image, while a `gamma > 1` will darken an image.\n",
    "\n",
    "Logarithmic correction adjusts contrast with a logarithmic function by applying the function `O = gain*log(1 + I)` pixelwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_low_val = 0.7\n",
    "gamma_low = skimage.exposure.adjust_gamma(data, gamma=gamma_low_val)\n",
    "\n",
    "gamma_high_val = 1.3\n",
    "gamma_high = skimage.exposure.adjust_gamma(data, gamma=gamma_high_val)\n",
    "\n",
    "log_val = 2\n",
    "log = skimage.exposure.adjust_log(data, gain=log_val)\n",
    "\n",
    "_, ((a, b, c, d), (f, g, h, i)) = plt.subplots(nrows=2, ncols=4, figsize=(16, 8))\n",
    "\n",
    "show_plane(a, data[32], title=\"Original\")\n",
    "show_plane(b, gamma_low[32], title=\"Gamma = {}\".format(gamma_low_val))\n",
    "show_plane(c, gamma_high[32], title=\"Gamma = {}\".format(gamma_high_val))\n",
    "show_plane(d, log[32], title=\"Log = {}\".format(log_val))\n",
    "\n",
    "plot_hist(f, data)\n",
    "plot_hist(g, gamma_low)\n",
    "plot_hist(h, gamma_high)\n",
    "plot_hist(i, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization) improves contrast in an image by adjusting the pixel intensity histogram. The most common pixel intensities are redistributed such that the equalized image has a linear cumulative distribution function. After histogram equalization, areas of lower local contrast gain a higher contrast. Histogram equalization often has an undesirable side-effect; it can enhance noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = skimage.exposure.equalize_hist(data)\n",
    "\n",
    "display(equalized)\n",
    "\n",
    "_, ((a, b), (c, d)) = plt.subplots(nrows=2, ncols=2, figsize=(16, 8))\n",
    "\n",
    "plot_hist(a, data, title=\"Original\")\n",
    "plot_hist(b, equalized, title=\"Histogram equalization\")\n",
    "\n",
    "cdf, bins = skimage.exposure.cumulative_distribution(data.ravel())\n",
    "c.plot(bins, cdf, \"r\")\n",
    "c.set_title(\"Original CDF\")\n",
    "\n",
    "cdf, bins = skimage.exposure.cumulative_distribution(equalized.ravel())\n",
    "d.plot(bins, cdf, \"r\")\n",
    "d.set_title(\"Histogram equalization CDF\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most experimental images are affected by salt and pepper noise. A few bright artifacts can decrease the relative intensity of the pixels of interest. A simple way to improve contrast is to clip the pixel values on the lowest and highest extremes. Clipping the darkest and brightest 0.5% of pixels will increase the overall contrast of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = scipy.stats.scoreatpercentile(data, (0.5, 99.5))\n",
    "\n",
    "clipped = skimage.exposure.rescale_intensity(\n",
    "    data, \n",
    "    in_range=(vmin, vmax), \n",
    "    out_range=np.float32\n",
    ").astype(np.float32)\n",
    "\n",
    "display(clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rescaled = clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection\n",
    "\n",
    "[Edge detection](https://en.wikipedia.org/wiki/Edge_detection) highlights regions in the image where a sharp change in contrast occurs. The intensity of an edge corresponds to the steepness of the transition from one intensity to another. A gradual shift from bright to dark intensity results in a dim edge. An abrupt shift results in a bright edge.\n",
    "\n",
    "The [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator) is an edge detection algorithm which approximates the gradient of the image intensity, and is fast to compute. `skimage.filters.sobel` has not been adapted for 3D images. It can be applied planewise to approximate a 3D result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel = np.empty_like(rescaled)\n",
    "\n",
    "for plane, image in enumerate(rescaled):\n",
    "    sobel[plane] = skimage.filters.sobel(image)\n",
    "    \n",
    "display(sobel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ((a, b), (c, d)) = plt.subplots(nrows=2, ncols=2, figsize=(16, 4))\n",
    "\n",
    "show_plane(a, sobel[:, 128, :], title=\"3D sobel, row = 128\")\n",
    "\n",
    "row_sobel = skimage.filters.sobel(rescaled[:, 128, :])\n",
    "show_plane(b, row_sobel, title=\"2D sobel, row=128\")\n",
    "\n",
    "show_plane(c, sobel[:, :, 128], title=\"3D sobel, column = 128\")\n",
    "\n",
    "column_sobel = skimage.filters.sobel(rescaled[:, :, 128])\n",
    "show_plane(d, column_sobel, title=\"2D sobel, column=128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "\n",
    "In addition to edge detection, `skimage.filters` provides functions for filtering and thresholding images.\n",
    "\n",
    "[Gaussian filter](https://en.wikipedia.org/wiki/Gaussian_filter) applies a Gaussian function to an image, creating a smoothing effect. `skimage.filters.gaussian` takes as input `sigma` which can be a scalar or a sequence of scalar. This `sigma` determines the standard deviation of the Gaussian along each axis. The spacing in the `plane` dimension is much greater than the `row` and `column` dimensions. Dividing `base_sigma` by the image `spacing` will reduce the contribution of pixels in the `plane` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sigma = 3.0\n",
    "\n",
    "sigma = np.divide(base_sigma, spacing)\n",
    "\n",
    "gaussian = skimage.filters.gaussian(rescaled, multichannel=False, sigma=sigma)\n",
    "\n",
    "display(gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Median filter](https://en.wikipedia.org/wiki/Median_filter) is a noise removal filter. It is particularly effective against salt and pepper noise. An additional feature of the median filter is its ability to preserve edges. This is helpful in segmentation because the original shape of regions of interest will be preserved.\n",
    "\n",
    "`skimage.filters.median` does not support three-dimensional images and needs to be applied planewise. The chosen structuring element, which defines the neighborhoods the filter is applied to, is smaller than the spacing in the `plane` dimension. No contribution from planes above and below each neighborhood is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_uint8 = skimage.img_as_ubyte(rescaled)\n",
    "\n",
    "median = np.empty_like(rescaled_uint8)\n",
    "\n",
    "selem = skimage.morphology.square(3)\n",
    "\n",
    "for plane, image in enumerate(rescaled_uint8):\n",
    "    median[plane] = skimage.filters.median(image, selem=selem)\n",
    "    \n",
    "median = skimage.img_as_float(median)\n",
    "    \n",
    "display(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, a [bilateral filter](https://en.wikipedia.org/wiki/Bilateral_filter) is an edge-preserving, denoising filter. Each pixel is assigned a weighted average based on neighboring pixels. The weight is determined by spatial and radiometric similarity (e.g., distance between two colors).\n",
    "\n",
    "`skimage.restoration.denoise_bilateral` requires a `multichannel` parameter. This determines whether the last axis of the image is to be interpreted as multiple channels or another spatial dimension. While the function does not yet support 3D data, the `multichannel` parameter will help distinguish multichannel 2D data from grayscale 3D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateral = np.empty_like(rescaled)\n",
    "\n",
    "for index, plane in enumerate(rescaled):\n",
    "    bilateral[index] = skimage.restoration.denoise_bilateral(\n",
    "        plane, \n",
    "        multichannel=False\n",
    "    )\n",
    "\n",
    "display(bilateral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (a, b, c, d) = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n",
    "\n",
    "show_plane(a, rescaled[32], title=\"Original\")\n",
    "show_plane(b, gaussian[32], title=\"Gaussian\")\n",
    "show_plane(c, median[32], title=\"Median\")\n",
    "show_plane(d, bilateral[32], title=\"Bilateral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denoised = bilateral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Thresholding](https://en.wikipedia.org/wiki/Thresholding_%28image_processing%29) is used to create binary images. A threshold value determines the intensity separating foreground pixels from background pixels. Foregound pixels are assigned a `True` value, background pixels are assigned `False`. Thresholding is a form of image segmentation. Thresholded images can also be used to mask images.\n",
    "\n",
    "Different thresholding algorithms produce different results. [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method) and Li's minimum cross entropy threshold are two common algorithms. The example below demonstrates how a small difference in the threshold value can visibly alter the binarized image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_li = skimage.filters.threshold_li(denoised)\n",
    "li = denoised >= threshold_li\n",
    "\n",
    "threshold_otsu = skimage.filters.threshold_otsu(denoised)\n",
    "otsu = denoised >= threshold_otsu\n",
    "\n",
    "_, (a, b, c) = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "plot_hist(a, denoised, \"Thresholds (Li: red, Otsu: blue)\")\n",
    "a.axvline(threshold_li, c=\"r\")\n",
    "a.axvline(threshold_otsu, c=\"b\")\n",
    "\n",
    "show_plane(b, li[32], title=\"Li's threshold = {:0.3f}\".format(threshold_li))\n",
    "show_plane(c, otsu[32], title=\"Otsu's threshold = {:0.3f}\".format(threshold_otsu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = li\n",
    "\n",
    "display(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mathematical morphology](https://en.wikipedia.org/wiki/Mathematical_morphology) operations and structuring elements are defined in `skimage.morphology`. Shapes, known as structuring elements, define areas over which an `erosion` or `dilation` operation is applied. The response to the filter indicates how well the neighborhood corresponds to that shape.\n",
    "\n",
    "There are a number of two and three dimensional structuring elements defined in `skimage.morphology`. Not all 2D structuring element have a 3D counterpart. The simplest and most commonly used structuring elements are the disk/ball and square/cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball = skimage.morphology.ball(5)\n",
    "print(\"ball shape: {}\".format(ball.shape))\n",
    "\n",
    "cube = skimage.morphology.cube(5)\n",
    "print(\"cube shape: {}\".format(cube.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic mathematical morphology operations are `dilation` and `erosion`. Dilation enlarges bright regions and shrinks dark regions. Erosion shrinks bright regions and enlarges dark regions. Other morphological operations are composed of `dilation` and `erosion`.\n",
    "\n",
    "The morphological `closing` on an image is defined as a `dilation` followed by an `erosion`. Closing can remove small dark spots (i.e. “pepper”) and connect small bright cracks. This tends to “close” up (dark) gaps between (bright) features.\n",
    "\n",
    "The morphological `opening` on an image is defined as an `erosion` followed by a `dilation`. Opening can remove small bright spots (i.e. “salt”) and connect small dark cracks. This tends to “open” up (dark) gaps between (bright) features.\n",
    "\n",
    "These operations in `skimage.morphology` are compatible with 3D images and structuring elements. A 2D structuring element cannot be applied to a 3D image, neither can a 3D structuring element be applied to a 2D image.\n",
    "\n",
    "These four operations (`closing`, `dilation`, `erosion`, `opening`) have binary counterparts which are faster to compute than the grayscale algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selem = skimage.morphology.ball(3)\n",
    "\n",
    "closing = skimage.morphology.closing(rescaled, selem=selem)\n",
    "dilation = skimage.morphology.dilation(rescaled, selem=selem)\n",
    "erosion = skimage.morphology.erosion(rescaled, selem=selem)\n",
    "opening = skimage.morphology.opening(rescaled, selem=selem)\n",
    "\n",
    "binary_closing = skimage.morphology.binary_closing(binary, selem=selem)\n",
    "binary_dilation = skimage.morphology.binary_dilation(binary, selem=selem)\n",
    "binary_erosion = skimage.morphology.binary_erosion(binary, selem=selem)\n",
    "binary_opening = skimage.morphology.binary_opening(binary, selem=selem)\n",
    "\n",
    "_, ((a, b, c, d), (e, f, g, h)) = plt.subplots(nrows=2, ncols=4, figsize=(16, 8))\n",
    "\n",
    "show_plane(a, closing[32], title=\"Closing\")\n",
    "show_plane(b, opening[32], title=\"Opening\")\n",
    "show_plane(c, erosion[32], title=\"Erosion\")\n",
    "show_plane(d, dilation[32], title=\"Dilation\")\n",
    "\n",
    "show_plane(e, binary_closing[32], title=\"Binary closing\")\n",
    "show_plane(f, binary_opening[32], title=\"Binary opening\")\n",
    "show_plane(g, binary_erosion[32], title=\"Binary erosion\")\n",
    "show_plane(h, binary_dilation[32], title=\"Binary dilation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphology operations can be chained together to denoise an image. For example, a `closing` applied to an `opening` can remove salt noise from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_equalized = equalized >= skimage.filters.threshold_li(equalized)\n",
    "\n",
    "despeckled1 = skimage.morphology.closing(\n",
    "    skimage.morphology.opening(binary_equalized),\n",
    "    selem=skimage.morphology.ball(1)\n",
    ")\n",
    "\n",
    "despeckled3 = skimage.morphology.closing(\n",
    "    skimage.morphology.opening(binary_equalized),\n",
    "    selem=skimage.morphology.ball(3)\n",
    ")\n",
    "\n",
    "_, (a, b, c) = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "show_plane(a, binary_equalized[32], title=\"Noisy data\")\n",
    "show_plane(b, despeckled1[32], title=\"Despeckled, r = 1\")\n",
    "show_plane(c, despeckled3[32], title=\"Despeckled, r = 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphological operations are useful for clearing salt and pepper noise from binary images. As illustrated in the example above, even a small structuring element can introduce distortions to the input image. Functions operating on [connected components](https://en.wikipedia.org/wiki/Connected_space) can remove smaller undesired elements while preserving larger shapes.\n",
    "\n",
    "`skimage.morphology.remove_small_holes` fills holes and `skimage.morphology.remove_small_objects` removes bright regions. Both functions accept a `min_size` parameter, which is the minimum size (in pixels) of accepted holes or objects. The `min_size` can be approximated by a cube. Scaling side length by `spacing` corrects the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 20\n",
    "\n",
    "remove_holes = skimage.morphology.remove_small_holes(\n",
    "    binary, \n",
    "    min_size=np.product(np.divide(a, spacing))\n",
    ")\n",
    "\n",
    "display(remove_holes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 40\n",
    "\n",
    "remove_objects = skimage.morphology.remove_small_objects(\n",
    "    remove_holes, \n",
    "    min_size=np.product(np.divide(a, spacing))\n",
    ")\n",
    "\n",
    "display(remove_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display label matrices with the background value set to black.\n",
    "def get_cmap(labels, name=\"viridis\"):\n",
    "    cmap = matplotlib.cm.get_cmap(\"viridis\")\n",
    "    masked_labels = np.ma.masked_where(labels == 0, labels)\n",
    "    cmap.set_bad(color=\"black\")\n",
    "    \n",
    "    return masked_labels, cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Image segmentation](https://en.wikipedia.org/wiki/Image_segmentation) partitions images into regions of interest. A thresholded image is also a segmented image. Interger labels are assigned to each region to distinguish regions of interest. These labels are used in [feature extraction](https://en.wikipedia.org/wiki/Feature_extraction); measurements such as total area or intensity statistics can be computed for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = skimage.measure.label(remove_objects)\n",
    "\n",
    "masked_labels, cmap = get_cmap(labels)\n",
    "\n",
    "display(masked_labels, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected regions of the binary image are assigned the same label via `skimage.measure.label`. Tightly packed cells are falsely connected in the binary image and are assigned the same label due to this connectedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (a, b, c) = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "show_plane(a, rescaled[32, :100, 125:], title=\"Rescaled\")\n",
    "show_plane(b, masked_labels[32, :100, 125:], cmap=cmap, title=\"Labels\")\n",
    "show_plane(c, labels[32, :100, 125:] == 8, title=\"Labels = 8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better segmentation would assign different labels to the regions which appear disjoint in the original image. [Watershed segmentation](https://en.wikipedia.org/wiki/Watershed_%28image_processing%29) can distinguish touching objects. Watershed works by flooding basins of low intensity until joined by adjacent flooded basins. For declumping, these basins are distinguished by markers generated from a distance image. Points furthest from an edge have the lowest intensity and should be identified as markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = ndi.distance_transform_edt(remove_objects)\n",
    "\n",
    "peak_local_max = skimage.feature.peak_local_max(\n",
    "    distance,\n",
    "    footprint=np.ones((15, 15, 15), dtype=np.bool),\n",
    "    indices=False,\n",
    "    labels=skimage.measure.label(remove_objects)\n",
    ")\n",
    "\n",
    "markers = skimage.measure.label(peak_local_max)\n",
    "\n",
    "labels = skimage.morphology.watershed(\n",
    "    -rescaled, \n",
    "    markers, \n",
    "    mask=remove_objects\n",
    ")\n",
    "\n",
    "masked_labels, cmap = get_cmap(labels)\n",
    "\n",
    "display(masked_labels, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watershed successfully distinguishes clumped objects in the thresholded image. Below are two examples of clumped objects successfully assigned unque labels. In the second row of images, the two cells touching the border of the image are assigned the same label. It is challenging to distinguish clumped objects near the borders of images. In practice, objects touching the border of the image are discarded before feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ((a, b, c), (d, e, f)) = plt.subplots(nrows=2, ncols=3, figsize=(16, 8))\n",
    "\n",
    "show_plane(a, masked_labels[32, :100, 125:], cmap=cmap, title=\"Labels\")\n",
    "show_plane(b, labels[32, :100, 125:] == 20, title=\"Labels = 20\")\n",
    "show_plane(c, labels[32, :100, 125:] == 21, title=\"Labels = 21\")\n",
    "\n",
    "show_plane(d, masked_labels[32, 75:175, 125:], cmap=cmap, title=\"Labels\")\n",
    "show_plane(e, labels[32, 75:175, 125:] == 13, title=\"Labels = 13\")\n",
    "show_plane(f, labels[32, 75:175, 125:] == 14, title=\"Labels = 14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The watershed algorithm falsely detected subregions in a few cells. This is referred to as oversegmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (a, b, c) = plt.subplots(nrows=1, ncols=3, figsize=(16, 8))\n",
    "\n",
    "show_plane(a, masked_labels[32, 156:, 20:150], cmap=cmap)\n",
    "show_plane(b, masked_labels[34, 90:190, 126:], cmap=cmap)\n",
    "show_plane(c, masked_labels[32, 150:, 118:248], cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the markers on the distance image reveals the reason for oversegmentation. Watershed assigns a unique label to each marker. Cells with multiple markers will be assigned multiple labes, and oversegmented. Markers are placed at local maxima. It can be observed that cells with a uniformly increasing distance map are assigned a single marker near their center. Cells with uneven distance maps are assigned multiple markers, indicating the presence of multiple local maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=3, ncols=4, figsize=(16, 12))\n",
    "\n",
    "vmin = distance.min()\n",
    "vmax = distance.max()\n",
    "\n",
    "for index, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(\n",
    "        distance[31 + index],\n",
    "        cmap=\"gray\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax\n",
    "    )\n",
    "    \n",
    "    peaks = np.nonzero(peak_local_max[31 + index])\n",
    "    \n",
    "    ax.plot(peaks[1], peaks[0], \"r.\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Feature extraction](https://en.wikipedia.org/wiki/Feature_extraction) reduces data required to describe an image or objects by measuring informative features. These include features such as area or volume, bounding boxes, and intensity statistics.\n",
    "\n",
    "Before measuring objects, it helps to clear objects from the image border. Measurements should only be collected for objects entirely contained in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interior_labels = skimage.segmentation.clear_border(labels)\n",
    "\n",
    "masked_labels, cmap = get_cmap(interior_labels)\n",
    "\n",
    "print(\"interior labels: {}\".format(np.unique(interior_labels)))\n",
    "\n",
    "display(masked_labels, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabeled, _, _ = skimage.segmentation.relabel_sequential(interior_labels)\n",
    "\n",
    "print(\"relabeled labels: {}\".format(np.unique(relabeled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionprops = skimage.measure.regionprops(relabeled, intensity_image=data)\n",
    "\n",
    "supported = [] \n",
    "unsupported = []\n",
    "\n",
    "for prop in regionprops[0]:\n",
    "    try:\n",
    "        regionprops[0][prop]\n",
    "        supported.append(prop)\n",
    "    except NotImplementedError:\n",
    "        unsupported.append(prop)\n",
    "\n",
    "print(\"Supported properties:\")\n",
    "print(\"  \" + \"\\n  \".join(supported))\n",
    "print()\n",
    "print(\"Unsupported properties:\")\n",
    "print(\"  \" + \"\\n  \".join(unsupported))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"measured regions: {}\".format(len(regionprops)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = [regionprop.area for regionprop in regionprops]\n",
    "\n",
    "print(\"area: {}\".format(area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_plane, min_row, min_col, max_plane, max_row, max_col = regionprops[3].bbox\n",
    "\n",
    "bbox_img = data[min_plane:max_plane, min_row:max_row, min_col:max_col]\n",
    "\n",
    "print(\"bounded image shape: {}\".format(bbox_img.shape))\n",
    "\n",
    "display(bbox_img, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts, faces, _, _ = skimage.measure.marching_cubes(labels == 3, level=0, spacing=(1.0, 1.0, 1.0))\n",
    "surface_area_pixels = skimage.measure.mesh_surface_area(verts, faces)\n",
    "\n",
    "verts, faces, _, _ = skimage.measure.marching_cubes(labels == 3, level=0, spacing=spacing)\n",
    "surface_area_actual = skimage.measure.mesh_surface_area(verts, faces)\n",
    "\n",
    "print(\"surface area (total pixels): {:0.2f}\".format(surface_area_pixels))\n",
    "print(\"surface area (actual): {:0.2f}\".format(surface_area_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
