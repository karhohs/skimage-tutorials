{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import scipy.stats\n",
    "import skimage.exposure\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.io\n",
    "import skimage.measure\n",
    "import skimage.morphology\n",
    "import skimage.restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display slices from a volume\n",
    "def display(volume, cmap=\"gray\"):\n",
    "    _, axes = plt.subplots(nrows=5, ncols=6, figsize=(16, 14))\n",
    "    \n",
    "    vmin = volume.min()\n",
    "    \n",
    "    vmax = volume.max()\n",
    "    \n",
    "    for ax, plane in zip(axes.flatten(), volume[::2]):\n",
    "        ax.imshow(\n",
    "            plane,\n",
    "            cmap=cmap,\n",
    "            vmax=vmax,\n",
    "            vmin=vmin\n",
    "        )\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        \n",
    "        ax.set_yticks([])\n",
    "\n",
    "# Display slices from a labeled volume\n",
    "def display_labels(labels, cmap_name=\"viridis\"):\n",
    "    cmap = matplotlib.cm.get_cmap(cmap_name)\n",
    "    \n",
    "    masked = np.ma.masked_where(labels == 0, labels)\n",
    "    \n",
    "    cmap.set_bad(color=\"black\")\n",
    "    \n",
    "    display(masked, cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three-dimensional image processing\n",
    "\n",
    "This tutorial aims to highlight some of the three-dimensional image processing functionality available in `skimage` by segmenting a cellular image provided by the Allen Institute for Cell Science. This tutorial is an adaptation of Emmanuelle Gouillart's [\n",
    "Segmentation of 3-D tomography images with Python and scikit-image](http://emmanuelle.github.io/segmentation-of-3-d-tomography-images-with-python-and-scikit-image.html). ðŸ’–\n",
    "\n",
    "`skimage` expects three-dimensional data to conform to `(plane, row, column[, channels])`. We will be working with a three-dimensonal grayscale image; the `channels` dimension is omitted.\n",
    "\n",
    "This three-dimensional image is composed of many two-dimensional images captured at different focal depths. Hence, the pixels between planes are spatially further from their row and column counterparts. We'll keep track of an additional variable `spacing` which describes the spacing between pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = skimage.io.imread(\"../images/cells.tif\")\n",
    "\n",
    "spacing = (0.29, 0.01625, 0.01625)\n",
    "\n",
    "print(\"shape: {}\".format(data.shape))\n",
    "\n",
    "print(\"dtype: {}\".format(data.dtype))\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by rescaling the image to the range `(0.0, 1.0)`, which is required by `skimage` when working with floating point data. \n",
    "\n",
    "Most experimental images are affected by salt and pepper noise. A few bright artifacts can decrease the relative intensity of the pixels of interest. Clipping the darkest and brightest 0.5% of pixels will increase the overall contrast of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = scipy.stats.scoreatpercentile(data, (0.5, 99.5))\n",
    "\n",
    "rescaled = skimage.exposure.rescale_intensity(\n",
    "    data, \n",
    "    in_range=(vmin, vmax), \n",
    "    out_range=np.float32\n",
    ").astype(np.float32)\n",
    "\n",
    "display(rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the contrast of the image has improved after clipping and rescaling. We'll apply a denoising operation to reduce the amount of salt and pepper noise in the image. `skimage.restoration.denoise_bilateral` is an an edge-preserving, denoising filter. It has not been adapted for three-dimensional data, but we can use it by applying the operation plane-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = np.empty_like(rescaled)\n",
    "\n",
    "for index, plane in enumerate(rescaled):\n",
    "    denoised[index] = skimage.restoration.denoise_bilateral(\n",
    "        plane, \n",
    "        multichannel=False\n",
    "    )\n",
    "\n",
    "display(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (a, b) = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "\n",
    "a.hist(data.flatten(), bins=32)\n",
    "a.set_title(\"Original\")\n",
    "\n",
    "b.hist(denoised.flatten(), bins=32)\n",
    "b.set_title(\"Denoised\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the pixel intensity histograms of the original and denoised data reveals a more favorable bimodal distribution in the denoised image. The two modes correspond to background and foreground pixels, respectively. `skimage.filters.threshold_li` will determine the threshold value separating foreground pixels from background pixels. We'll use the threshold value to create a binary image for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = skimage.filters.threshold_li(denoised)\n",
    "\n",
    "binary = denoised >= threshold\n",
    "\n",
    "_, (a, b) = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "\n",
    "a.hist(denoised.flatten(), bins=32)\n",
    "a.axvline(threshold, c=\"r\")\n",
    "a.set_title(\"Threshold = {:0.3f}\".format(threshold))\n",
    "\n",
    "b.imshow(binary[32], cmap=\"gray\")\n",
    "b.set_title(\"Thresholded image (plane = 32)\");\n",
    "\n",
    "display(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary image has two undesirable features: darker regions of the cell interiors were identified as background pixels, and brighter pixels in the noisy planes near the top and bottom of the image were identified as foreground pixels.\n",
    "\n",
    "We can fill holes uing the `skimage.morphology.remove_small_holes` function. Likewise, unwated objects can be removed using `skimage.morphology.remove_small_objects`. The `min_size` parameter determines a small hole or object in total pixels. An easy approximation of size is the smallest cube which encompasses a hole or object to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_spacing = tuple(np.divide(spacing[1], spacing))\n",
    "\n",
    "print(\"normalized spacing: {}\".format(normalized_spacing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 30\n",
    "\n",
    "removed_small_holes = skimage.morphology.remove_small_holes(\n",
    "    binary, \n",
    "    min_size=np.product(np.multiply(a, normalized_spacing))\n",
    ")\n",
    "\n",
    "display(removed_small_holes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 30\n",
    "\n",
    "removed_small_objects = skimage.morphology.remove_small_objects(\n",
    "    removed_small_holes,\n",
    "    min_size=np.product(np.multiply(a, normalized_spacing))\n",
    ")\n",
    "\n",
    "display(removed_small_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This binary image is a good segmentation of the original image. We could apply `skimage.measure.label` to assign unique labels to disjoint image regions. Connected regions in the binary image are assigned the same label (this can be observed by running the cell below). A better segmentation would assign different labels to the regions which appear disjoint in the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = skimage.measure.label(removed_small_objects)\n",
    "\n",
    "_, (a, b, c) = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "a.imshow(rescaled[30, :100, 125:], cmap=\"gray\")\n",
    "a.set_title(\"Rescaled\")\n",
    "\n",
    "b.imshow(labels[30, :100, 125:])\n",
    "b.set_title(\"Labels\")\n",
    "\n",
    "c.imshow(labels[30, :100, 125:] == 8, cmap=\"gray\")\n",
    "c.set_title(\"Labels = 8\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watershed segmentation can distinguish touching objects, an operation referred to as declumping. Watershed works by flooding basins of low intensity until joined by adjacent flooded basins. For declumping, these basins are distinguished by markers generated from a distance image. Points furthest from an edge have the lowest intensity and should be identified as markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = ndi.distance_transform_edt(removed_small_objects)\n",
    "\n",
    "peak_local_max = skimage.feature.peak_local_max(\n",
    "    distance,\n",
    "    footprint=np.ones((15, 15, 15), dtype=np.bool),\n",
    "    indices=False,\n",
    "    labels=skimage.measure.label(removed_small_objects)\n",
    ")\n",
    "\n",
    "markers = skimage.measure.label(peak_local_max)\n",
    "\n",
    "labels = skimage.morphology.watershed(\n",
    "    -rescaled, \n",
    "    markers, \n",
    "    mask=removed_small_objects\n",
    ")\n",
    "\n",
    "display_labels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The declumping step has over-segmented a few regions of interest. We can inspect the `distance` image and plot the markers to understand where the basins for the watershed are being defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=2, ncols=6, figsize=(16, 5))\n",
    "\n",
    "vmin = distance.min()\n",
    "\n",
    "vmax = distance.max()\n",
    "\n",
    "for index, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(\n",
    "        -distance[30 + index],\n",
    "        cmap=\"gray\",\n",
    "        vmin=-vmax,\n",
    "        vmax=-vmin\n",
    "    )\n",
    "    \n",
    "    peaks = np.nonzero(peak_local_max[30 + index])\n",
    "    \n",
    "    ax.plot(peaks[1], peaks[0], \"r.\")\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    \n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objects we're trying to identify aren't perfectly smooth. Natural variations in shape, such as figure eights, are falsely declumped. Additionally, the objects with holes or gaps near their ends were oversegmented. This could be due to the nonuniformity in the distance image or by searching small regions for makers in `skimage.feature.peak_local_max`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge problems\n",
    "\n",
    "### Improve the segmentation\n",
    "\n",
    "A few objects were oversegmented in the declumping step. Try to improve the segmentation and assign each object a single, unique label. You can try:\n",
    "\n",
    "1. generating a smoother image by modifying the `win_size` parameter in `skimage.restoration.denoise_bilateral`, or try another filter. Many filters are available in `skimage.filters` and `skimge.filters.rank`.\n",
    "1. adjusting the threshold value by trying another threshold algorithm such as `skimage.filters.otsu` or entering one manually.\n",
    "1. generating different markers by changing the size of the `footprint` passed to `skimage.feature.peak_local_max`. Alternatively, try another distance function or limit the planes on which markers can be placed.\n",
    "\n",
    "### Bonus challenge: segment the membrane channel\n",
    "\n",
    "If segmenting the nuclei was too easy, try segmenting the accompanying membrane channel. You can load the membrane image with `skimage.io.imread`:\n",
    "\n",
    "```python\n",
    "membrane = skimage.io.imread(\"../images/cells_membrane.tif\")\n",
    "```\n",
    "\n",
    "Hint: There should be one nuclei per membrane object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
